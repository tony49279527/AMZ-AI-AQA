# 实施路线图与测试里程碑

> 总结要实现的全部功能、实施顺序、何时可以开始测试「非常详细的报告」，以及工程量与时间预估。

---

## 一、功能总结（我们要做哪些事）

| 大类 | 功能点 | 说明 |
|------|--------|------|
| **前端** | FormData 提交 + 文件上传 | 新建报告页：提交时用 FormData，包含 payload（JSON）+ 可选 returnsFile、audienceFile |
| **前端** | 报告语言选择 | 增加「报告语言」下拉（如 中文+英文、中文+德语），提交字段 reportLanguage |
| **前端** | 数据源 Tab 总览 | 报告详情页「数据源」Tab：一行一条列出用了哪些数据（类型 + 链接/ASIN + 约 X 字），不展示正文 |
| **后端** | FormData 解析 | generate 接口改为 request.formData()，取 payload、returnsFile、audienceFile |
| **后端** | 上传文件解析 | 退货报告、人群画像：CSV/TXT 解析为文本；无则 NO_RETURN_REPORT / NO_PERSONA_REPORT |
| **后端** | 六块数据组装 | 产品信息、评论、参考网站、参考 YouTube、退货、人群 → 拼成 6 段文本 |
| **后端** | 单次模板生成报告 | 用 System + User 提示词模板替换 10 个占位符，一次 OpenRouter 调用，整份报告写 report_<id>.md |
| **后端** | 评论接入 | 调用 fetchCombinedReviewsFromRapidAPI，结果作为 COMBINED_REVIEWS 注入 |
| **后端** | 抓取资料入库 | 建表 report_sources；生成时每抓一块写一条（含 content、char_count 等）；正文只存库，不返给前端 |
| **后端** | 数据源列表 API | GET /api/reports/:reportId/sources，返回摘要列表（无 content），供数据源 Tab 展示 |
| **后端** | 问答使用抓取资料 | 问答接口按 report_id 查 report_sources，把 content 与报告正文一起做检索/上下文 |

**阶段二（可选、依赖你提供接口）**：按关键词自动发现参考网站/YouTube、Excel 解析、YouTube 字幕等，见实现计划文档。

---

## 二、实施阶段划分

### 阶段 1a：跑通「提交 → 单次生成报告」（第一次可测）

**目标**：用户能提交表单（含主品/竞品、报告语言、核心提示词、可选 webUrls、可选退货/人群文件），后端拉产品信息 + 用户填的网页，拼 6 块，用你的模板**一次**生成整份报告，并在详情页看到报告正文。

| 序号 | 任务 | 说明 |
|------|------|------|
| 1a-1 | 前端：FormData 提交 | 新建报告页：body 改为 FormData，payload 为 JSON 字符串，有文件时追加 returnsFile、audienceFile |
| 1a-2 | 前端：报告语言 | 增加报告语言选择，提交 reportLanguage（如「英文」） |
| 1a-3 | 后端：FormData 解析 | generate 里 request.formData()，取 payload 并 JSON.parse，取两个 file |
| 1a-4 | 后端：文件解析 | 解析 returnsFile、audienceFile 为文本（先 TXT + CSV）；无文件则占位符 NO_* |
| 1a-5 | 后端：单次模板生成 | 组装 PRODUCTS_INFO（现有 RapidAPI）、COMBINED_REVIEWS（先空或「暂无」）、COMBINED_WEB_CONTENT（现有 webUrls+ScrapingBee）、COMBINED_TRANSCRIPT（空）、退货/人群；替换模板 10 个占位符；**一次** OpenRouter 调用；写 report_<id>.md + metadata |
| 1a-6 | 后端：SSE 与进度 | 保留 init/log/progress/complete，log 输出「拉取产品信息」「抓取网页」「生成报告中」等 |

**交付**：提交后能得到**一整份**按你框架生成的报告（产品信息 + 用户填的网页会进报告；评论、YouTube 可为空）。  
**可测试**：✅ **这里就可以第一次测试「详细报告」**——用真实主品/竞品 ASIN、核心提示词、可选 1～2 个 webUrls、可选上传退货/人群文件，看报告结构、字数、中英混排是否满足预期。

---

### 阶段 1b：评论接入 + 数据更完整（第二次可测）

**目标**：评论真实拉取并注入报告，报告内容更贴近 n8n（含主品/竞品评论分析）。

| 序号 | 任务 | 说明 |
|------|------|------|
| 1b-1 | 后端：评论注入 | 在 generate 里调用 fetchCombinedReviewsFromRapidAPI(allAsins, marketplace, { maxPerAsin: 100 })，结果作为 COMBINED_REVIEWS 填入模板 |
| 1b-2 | 错误与占位 | 评论接口失败时该块为空或「评论拉取失败，已跳过」，不阻塞整份报告生成 |

**交付**：报告里会包含「产品评论」相关分析。  
**可测试**：✅ **第二次测试「非常详细的报告」**——同一批数据，报告应明显更详实（含评论要点、主品/竞品对比）。

---

### 阶段 1c：数据来源入库 + 数据源 Tab 总览

**目标**：抓到的每块资料写入数据库；报告详情页「数据源」Tab 展示一行一条总览（不展示正文）。

| 序号 | 任务 | 说明 |
|------|------|------|
| 1c-1 | 数据库：建库建表 | 新增 SQLite + 表 report_sources（report_id, source_type, source_key, display_label, content, char_count, created_at） |
| 1c-2 | 后端：生成时写库 | 每抓到一块（产品/评论/网站/YouTube/退货/人群）就插入 report_sources；content 存库，供后续问答用 |
| 1c-3 | 后端：GET sources API | GET /api/reports/:reportId/sources，按 report_id 查表，返回列表（不含 content），含 source_type、display_label/source_key、char_count |
| 1c-4 | 前端：数据源 Tab | 调用上述 API，在「数据源」Tab 一行一条渲染：类型 · 链接/ASIN/用户上传 · 约 X 字 |

**交付**：用户能清楚看到「本报告用了哪些数据」；完整正文在库中，供后续问答。  
**可测试**：✅ 报告详情页「数据源」Tab 是否有正确条数、链接可点、字数合理。

---

### 阶段 1d：问答使用抓取资料（可选，紧跟 1c）

**目标**：智能问答不仅基于报告正文，还基于已抓取的资料（产品、评论、网页、字幕等）。

| 序号 | 任务 | 说明 |
|------|------|------|
| 1d-1 | 后端：问答读 report_sources | 在 chat 接口中，按 report_id 查询 report_sources，取 content |
| 1d-2 | 检索与上下文 | 报告章节 + 来源 content 一起做关键词/简单检索，取 Top-K 拼入上下文 |
| 1d-3 | 提示词 | 在 system/user 中说明可引用「报告」与「抓取资料」，并标注来源 |

**交付**：用户问「某条评论里说了什么」「某个网站提到什么」时，模型能基于库中资料回答。

---

### 阶段 2：自动发现网站/视频、Excel、体验优化（依赖与可选）

- 按关键词自动发现参考网站/YouTube：需你提供搜索 API（如 SerpApi）、YouTube 字幕方式。
- 退货/人群支持 Excel：解析 .xlsx。
- 进度阶段化、单源失败不阻塞、超时重试等。

---

## 三、何时可以开始测试「非常详细的报告」

| 里程碑 | 阶段 | 能测到什么 |
|--------|------|------------|
| **第一次可测** | **阶段 1a 完成** | 提交表单 → 得到**一整份**按你框架生成的报告（产品信息 + 用户填的网页 + 可选退货/人群）；评论、YouTube 可为空。可验证：框架、字数、语言、表格等。 |
| **第二次可测** | **阶段 1b 完成** | 同上，且报告内包含**真实评论**分析，更接近 n8n 的详细程度。 |
| **完整可测** | **阶段 1c 完成** | 报告 + **数据源 Tab 总览**（一行一条，知道用了哪些数据）；抓取内容已入库，为问答做准备。 |

建议：**阶段 1a 做完就做第一次详细报告测试**，用你 n8n 用过的同一批输入，对比结构和质量；1b 做完再测一轮带评论的报告；1c 做完验收数据源展示与入库。

---

## 四、工程量与时间预估（参考）

按**单人、熟悉本代码库**估算（人天 = 工作日；若多人可并行部分任务）。

| 阶段 | 主要任务量 | 预估人天 | 说明 |
|------|------------|----------|------|
| **1a** | 前端 FormData + 报告语言；后端 formData + 文件解析 + 6 块组装 + 单次模板调用 + SSE | **3～5 天** | 改动点明确但涉及 generate 全流程重写，需联调 |
| **1b** | 评论接口接入 + 占位与错误处理 | **0.5～1 天** | 数据源已有，主要是拼进模板与容错 |
| **1c** | SQLite 建表 + 生成时写库 + GET sources API + 数据源 Tab 前端 | **2～3 天** | 首次引入 DB，需确认部署方式（SQLite 文件位置等） |
| **1d** | 问答读 report_sources + 检索与上下文 + 提示词 | **1.5～2.5 天** | 依赖 1c；检索逻辑可先简单关键词 |
| **合计（1a～1c）** | — | **约 5.5～9 天** | 到「完整可测」：详细报告 + 数据源总览 |
| **合计（含 1d）** | — | **约 7～11.5 天** | 含问答基于抓取资料 |

- **只做到「第一次可测详细报告」**：约 **3～5 天**（阶段 1a）。  
- **做到「第二次可测（带评论）+ 数据源 Tab」**：约 **5.5～9 天**（1a + 1b + 1c）。  
- **再算上问答用抓取资料**：约 **7～11.5 天**（再加 1d）。

以上为开发时间，不含你本地环境、Key 配置、以及你反复对比 n8n 报告的测试时间；若遇到 RapidAPI/ScrapingBee 限流或返回格式差异，可能多 0.5～1 天排查。

---

## 五、分块测试优先（避免反复全流程消耗 API）

全流程一次会同时消耗 RapidAPI、ScrapingBee、OpenRouter；若中间某一步失败，整次请求的配额都浪费，且可能触发限流。因此采用 **先分块测、再全流程测** 的策略。

- **做法**：每个模块（产品信息、评论、网页抓取、文件解析、模板填充、OpenRouter）都有**独立可测**的方式（如 `scripts/test-rapidapi-product.mjs`、`scripts/test-scrapingbee.mjs` 等），用 **1 个 ASIN / 1 个 URL / 1 个小文件** 单独跑通，确认成功后再接到报告生成主流程。
- **全流程测试**：只在各块都通过后，跑 **1～2 次** 完整报告做最终验收。
- 详见：**`docs/分块测试策略.md`**（模块清单、测试顺序、脚本/接口建议）。

实施时建议：**先写各块的测试脚本并跑通**，再做阶段 1a/1b 的集成；这样不会因为「一次写不全」而反复烧 API。

---

## 六、建议执行顺序（一页总览）

```
0. 分块可测（先做）
   → 为 A/B/C/D/E/F 各写独立测试脚本（或测试接口），你本地用 1 个 ASIN/1 个 URL 等逐块验证
   → 通过后再接主流程，避免全流程一次失败浪费配额

1. 阶段 1a（3～5 天）
   → FormData + 报告语言 + 文件解析 + 单次模板生成
   → ✅ 第一次全流程测试「详细报告」（仅 1～2 次）

2. 阶段 1b（0.5～1 天）
   → 评论接入
   → ✅ 第二次全流程测试「带评论的详细报告」

3. 阶段 1c（2～3 天）
   → 建库 + 写库 + GET sources API + 数据源 Tab
   → ✅ 验收数据源总览与入库

4. 阶段 1d（1.5～2.5 天，可选）
   → 问答使用 report_sources

5. 阶段 2（按需）
   → 自动发现网站/视频、Excel、体验优化
```

先完成 **分块可测 + 1a** 即可在最少全流程次数下测试非常详细的报告；完成 **1a+1b+1c** 即具备「详细报告 + 数据来源可追溯 + 资料入库」的完整闭环。
